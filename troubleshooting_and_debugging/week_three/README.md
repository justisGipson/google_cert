# Troubleshooting and Debugging Techniques - Week 3

## Why Programs Crash

### Systems That Crash

Reduce the scope of the problem by starting with the actions that are easier and faster to check. Start with the
actions that are the easiest and fastest to check.

1. Try looking at the logs to see if there's any error that may point to what's happening

2. Try moving away the local configuration for the program and using the default configuration/reinstall the application

3. Try checking if it is some hardware component failure

---

### Understanding Crashing Applications

When an application crashes and we aren't sure why, the first thing we should do is check the logs.

To look at logs on Linux will open the **system log** files and **VAR log** or the **user log** files and **dot
 accession errors** file. On Mac OS we generally use the **Console App** to look at logs and the **Event Viewer** on
  Windows.

In most logs there will be a date and time for each line logged, showing when the application crashed. And you should
 be able to find an error message associated with the application or timestamp.
 
 Sometimes the errors will be self-explanatory:
        
        Permission Denied
        No Such File
        Directory Connection Refused
        
Sometimes the error messages will be cryptic, can always search online for official docs on the error or other
 examples that people have ran into.
 
Many applications generate a lot more output when debugging logging is enabled. Might need to be enabled from within
 an application or through a config file or through a command line parameter to pass when running the application
  manually. By enabling the extra logging info, we can get a better idea of whats causing the issue.
  
When there are no logs for us to use, we turn to tools that will help see what's going on.

* **strace** on linux to see what system calls a program is making
* **dtruss** MacOS equivalent tool
* **Process Monitor** on Windows

By tracing which system calls a program is doing we can see what files and directories it's trying open, what network
 connections it's trying to make, and what information it's trying to read or write.

It's valuable to spend some time figuring out the state that triggers the crash. This includes the overall system
 environment the specific application configuration the inputs to the application the outputs generated by the
  application the resources that uses and the services it communicates with.
  
When trying create the reproduction case it might be useful to start from a clean slate and slowly put the pieces
in place until the crash triggers. This might include trying out the application with the default configuration
instead of the local one or on a freshly installed computer instead of the computer where it's crashing. And 
remember we want to make the reproduction case as small as possible this lets us better understand the problem and
 also quickly check if its present or not when we attempt to fix it.

---

### What to do when you can't fix the program

Use **Wrappers** when the expected output and input formats don't match. A **Wrapper** is a function or program that provides a compatibility layer between two functions or programs so they can work well together.

Run the application inside a **virtual machine** or maybe a **container** if there's another application that requires a different version of the same library or you can't change a certain configuration setting because it's required to access a different service.

Deploy a **watchdog** when we can't find a way to stop an application from crashing but we can make sure that if it crashes it starts back again. This is a process that checks whether a program is running and when it's not starts the program again. To implement this, write a script that stays running in the background and periodically checks if the other program is running.

To report a bug - share good reproduction case(s) and by answering the following questions:

        * What were you trying to do?
        
        * What were the steps you followed?
        
        * What did you expect to happen?
        
        * What was the actual outcome?

---

### Internal Server Error

When a webpage on a Web server isn't working,

1. Try looking at logs
    * On Linux systems, logs are located in **/var/log**
    * Use the **date** command to check the current date
    * **ls -lt** command which sorts the files by the last modified date
    * pipe it to the head command to keep the top 10 lines
    
2. Use the **netstat** command which can give us information about our network connections depending on the flags
  passed
    * This command accesses different sockets that are restricted to **root** the administrator user on Linux - call it
     with sudo
    * Run commands as root, and then pass different flags with netstat
    * Use **-n** to print numerical addresses instead of resolving host names
    * Use **l** to only check out the sockets that are listening for connection
    * Use **p** to print the process ID and name to which each socket belongs
    * Since we are interested in **port 80**, connect the output to a **grep** command checking for `:80` - the Web
     server is usually running on port 80, the default web serving port
        `sudo netstat -nlp | grep :80`
        
### Resources for Understanding Crashes

There's a ton of different reasons why a computer might crash. This [Scientific American article](https://www.scientificamerican.com/article/why-do-computers-crash/) discusses many of the possible reasons, including hardware problems and issues with the overall operating system or the applications on top.

On Linux or MacOS, the worst kind of crash is called a Kernel Panic. On Windows, it's known as the [Blue Screen of
 Death](https://en.wikipedia.org/wiki/Blue_Screen_of_Death) These are situations where the computer completely stops responding and only a reboot can make it work again. They don't happen often, but it's good to understand what they mean: the whole OS encountered an error and it can't recover.
 
 We called out that reading logs is super important. You should know how to read logs on the operating system that you're using. Here are some resources for this:
 
 * [How to find logs on Windows10](https://www.digitalmastersmag.com/magazine/tip-of-the-day-how-to-find-crash-logs
 -on-windows-10/) (Digital Masters Magazine)
 * [How to view System Logs on a Mac](https://www.howtogeek.com/356942/how-to-view-the-system-log-on-a-mac/) (How To
  Geek)
 * [How to view System Logs on Linux](https://www.fosslinux.com/8984/how-to-check-system-logs-on-linux-complete-usage
 -guide.htm) (FOSS Linux)
 
 You also need to be familiar with the tools available in your OS to diagnose problems. These are the tools we called out, but you don't need to limit yourself to them:
 
 * [Process Monitor](https://docs.microsoft.com/en-us/sysinternals/downloads/procmon) (Microsoft)
 * [Linux strace command for beginners](https://www.howtoforge.com/linux-strace-command/) (HowToForge)
 * [How to trace system call on Mac](https://etcnotes.com/posts/system-call/) (/etc/notes)
    
---

## Code that Crashes

### Accessing Invalid Memory

One common reason a program crashes is it's trying to access invalid memory. Accessing invalid memory means that the
 process tried to access a portion of the system's memory that wasn't assigned to it.
 
During normal working conditions, applications will request a portion of the memory and then use the space the OS
 assigned them. Programming errors might lead to a process trying to read or write to a memory address outside of the
  valid range. 

In low-level languages like C or C++, the variables that store memory addresses are called pointers and the
 programmer needs to take care of requesting the memory that the program is going to use and then giving that memory
  back once it's not needed anymore. In these languages the variables that store memory addresses are called
   **pointers**, they're just like any other variables as they can be modified as needed. So if a pointer is set to a
    value outside of the valid memory range for that process, it will point to invalid memory. 

When a program tries to read or write to a memory address outside of the valid range, the OS will raise an error like
 **segmentation fault** or **general protection fault**.

Common programming errors that lead to segmentation faults or segfaults include,

* Forgetting to initialize a variable

* Trying to access a list element outside of the valid range

* Trying to use a portion of memory after having given it back

* Trying to write more data than the requested portion of memory can hold

The **debugger** can give you a lot more detail on what the application is doing and why the memories invalid. For this to be possible, we'll need our program to be compiled with debugging symbols. This means that on top of the information that the computer uses to execute the program, the executable binary needs to include extra information needed for debugging, like the names of the variables and functions being used.

Linux distributions like Debian or Ubuntu ships separate packages with the debugging symbols for all the packages in the distribution. Microsoft compilers can also generate debugging symbols in a separate PDB file.

One of the trickiest things about invalid memory is that we're usually dealing with **Undefined behavior
**. **Undefined behavior** is when the code is doing something that isn't valid in the programming language. The
 actual outcome will depend on the compiler used, how the operating system assigns memory to processes, and even the
 version of the libraries in use

**Valgrind** can help when trying to understand problems related to handling invalid memory. **Valgrind** is a very
 powerful tool that can tell us if the code is doing any invalid operations no matter if it crashes are not. Valgrind lets us know if the code is accessing variables before initializing them.

**Valgrind** is available on Linux and Mac OS, and Dr. Memory is a similar tool that can be used on both Windows and
 Linux.

---

### Unhandled Errors and Exceptions

When a program comes across an unexpected condition that isn't correctly handled in the code, it will trigger errors
 or exceptions.

In Python, following errors could occurs,

* **Index error** if we tried to access an element after the end of a list

* **Type error** or an **attribute error** if we try to take an action on a variable that wasn't properly initialized

* **Division by zero error** if we tried to divide by zero

These kind of errors are what will cause a program to finish unexpectedly.

When these failures happen, the interpreter that's running the program will print the following:

* Type of error

* Line that caused the failure

* **Traceback** which shows the lines of the different functions that were being executed when the problem happened

To find out where things are going wrong, we use **debugging tools** available for the application's language

For a Python program we can use the **BDB interactive debugger** which lets us do all the typical debugging actions
 like executing lines of code one-by-one or looking at how the variables change values.

When we're trying to understand what's up with a misbehaving function on top of using debuggers, it's 
common practice to trying to understand what's up with a misbehaving function on top of using debuggers. It adds
statements that print data related to the codes execution to show the contents of variables, the return values of
functions or metadata like the length of a list or size of a file. This is called **print f debugging**. Taking a
step further, the best approach is to add the messages in a way that can be easily enabled or disabled depending on
whether we want the debug info or not.

In Python, use the **logging module** which lets us set how comprehensive we want our code to be. We can set
whether we want all debugging messages, only info warnings or error messages. When printing the message we specify
what type of message we're printing, so we can change the debug level with a flag or configuration setting.

In general, you'll want to make the program more resilient to failures. Instead of crashing unexpectedly, you want
the program to inform the user of the problem and tell them what they need to do

---

### Fixing Someone Else's Code

Writing good comments and having well-documented functions is one of those good habits that pays off when trying to
understand code written by others and also your past self. 

Writing comments help you solidify your understanding of the code. Another thing that can help to understand someone
else's code is reading the tests associated to the code. Well-written tests can tell us what each function is
expected to do. Looking at the existing tests can show us which use cases weren't taken into account.

Just like with writing extra comments, writing some tests of your own can help you better see what the code is
supposed to do and improve overall quality of the code. This can also be really useful when modifying the original code.

One possible approach in this case, would be to start with the function where the error happened, then the function
or functions that call it, and so on until you can grasp the contexts that led to the problem. While this is of
course much easier if it's in a programming language that you're familiar with, you don't need to be an expert in the
language to fix a bug in the program. If you've come across an error and debug the issue well enough to understand
what's going on, you might be able to fix the problem even if you've never seen that language before. Another thing
that can help to understand someone else's code is reading the tests associated to the code. 

---

### Debugging a Segmentation Fault

When an application crashes, it's useful to have a **core file** of the crash.

**Core files** store all the information related to the crash so that we or someone else can debug what's going on. 

It's like taking a snapshot of the crash when it happens to analyze it later.

In order to enable OS to generate core file,

1. Run the **ulimit** command

2. Use the **-c** flag for core files

3. use the **unlimited** to state that we want core files of any size

For the exercise shown in the video, it debugs **off-by-one error** by

1. Generated a core file and check the file using **ls -l** command

2. Use **gdb -c core \<executable>** to give it a core file and tell it where the executable that crashed is located

3. Use the **backtrace** command to look at the full backtrace of the crash

4. Use the **up** command to move to the calling function in the backtrace and check out the line and copy parameters
 that caused the crash

5. Use the **list** command that shows the lines around the current one to get more contexts for the code that failed

6. Print the contents of the first element argv 0, and then the second element argv 1

    * Zero is never a valid pointer
    
**Segmentation Faults are common error to encounter in C or C++ crashes**

### Debugging a Python Crash

**Unexpected Exceptions are common errors to encounter in Python crashes**

In unexpected exception trace backs we will see a few things.

* At the bottom is the name of the exception and a message

* List of function calls each being 2 lines
    
    * First line is the Python file that contains the function, the line number, and the name of the function
    
    * Second line shows us the contents of the line
 
 Similar to the backtrace in the segfault example, but the order of functions is reversed.
 
 Frequently, knowing the exception message and the line where the exception happened, is already enough to understand
 what's going on
 
 **pdb3 \<script> \[params]** starts the python debugger.
 
**Byte Order Mark** or **BOM** which is used in UTF-16 to tell the difference between a file stored using **Little
-endian** and **Big-endian**. Our file is in UTF-8 so it doesn't need the BOM. But some programs still include it and
this is tripping up our script

There is a special value called **UTF-8-sig** that we can set as the encoding parameter of the open function. Setting
this encoding means that Python will get rid of the BOM

We've barely scratched the surface of the many operations that we can do with debuggers. There are ton more advanced
debugging features. Like setting **breakpoints** the let our code run until certain line of code is executed or
**watchpoints** that let our code run until a variable or expression changes. We can also step through the code
instruction by instruction to check when a problem happens

### Extra Crash Debugging Resources

* [Python Concurrency](https://realpython.com/python-concurrency/)

* [Threaded Asynchronous Magic](https://hackernoon.com/threaded-asynchronous-magic-and-how-to-wield-it-bba9ed602c32)

* [Common Segmentation Fault Reasons](https://stackoverflow.com/questions/33047452/definitive-list-of-common-reasons-for-segmentation-faults)

* [Debugging Segmentation Faults](https://sites.google.com/a/case.edu/hpcc/home/important-notes-for-new-users/debugging-segmentation-faults)

### Example of Readable Python

* [Minecraft](https://github.com/fogleman/Minecraft)

* [Cherry Py](https://github.com/cherrypy/cherrypy)

* [Flask](https://github.com/pallets/flask)

* [Tornado](https://github.com/tornadoweb/tornado)

* [HowDoI](https://github.com/gleitz/howdoi)

* [Bottle.py](https://github.com/bottlepy/bottle/blob/master/bottle.py)

* [SQLAlchemy](https://github.com/sqlalchemy/sqlalchemy)

---

## Handling Bigger Incidents

### Crashes in Complex Systems

Below is troubleshoot strategies that can be used when handling crashes in complex systems,

1. Logs with useful information
    * The logs will contain the error messages from the server providing the service that's failing
    
    * General system logs will help indicate if there's an issue with the server in general
    
    * Essential to understanding what's going on

2. Roll back
    * It is the best strategy to use when the new changes are suspected to be causing the issue
   
    * It restores the service back to normal health if it was the cause
   
    * It helps eliminate new change as a possible cause if doing the rollback doesn't help

3. Monitoring of what the service is doing  

4. Use version control for quick roll back if needed

5. Deploy new machines if needed

---

### Communication and Documentation During Incidents

Forgetting to document could:

* Risk forgetting some important details

* Wasting a lot of valuable time when the same issue is revisited

Good document should contain the following:

* Root cause

* How you diagnose the problem and found that root cause

* What you did to fix the issue and what needs to be done to prevent the problem from happening again

---

### Writing Effective Postmortems

**Postmortems** are documents that describe details of incidence to help us learn from our mistakes. The goal of
postmortems is to learn from what happened to prevent the same issue from happening again.

In general a postmortem should include:

* Details of what caused the issue

* What the impact of the issue was

* How it got diagnosed

* Short-term remediation you applied

* Long-term remediation you recommend
